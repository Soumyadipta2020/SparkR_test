{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# docker run -it --name sparkr-jupy --mount type=bind,source=C:/Users/soumy/OneDrive/Coding,target=/app/data --rm -p 8888:8888 quay.io/jupyter/all-spark-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘SparkR’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var, window\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.data.frame, colnames, colnames<-, drop, endsWith, intersect,\n",
      "    rank, rbind, sample, startsWith, subset, summary, transform, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:SparkR’:\n",
      "\n",
      "    arrange, between, coalesce, collect, contains, count, cume_dist,\n",
      "    dense_rank, desc, distinct, explain, expr, filter, first, group_by,\n",
      "    intersect, lag, last, lead, mutate, n, n_distinct, ntile,\n",
      "    percent_rank, rename, row_number, sample_frac, select, slice, sql,\n",
      "    summarize, union, where\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(SparkR)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "# Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in sparkR.session():\n",
      "“SparkR is deprecated from Apache Spark 4.0.0 and will be removed in a future version.”\n",
      "Spark package found in SPARK_HOME: /usr/local/spark\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /usr/local/spark/bin/spark-submit   sparkr-shell /tmp/RtmpehmGGR/backend_port137b1f2e70f1 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Java ref type org.apache.spark.sql.SparkSession id 1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in sparkR.session(master = \"local[*]\", sparkConfig = list(spark.driver.memory = \"2g\")):\n",
      "“SparkR is deprecated from Apache Spark 4.0.0 and will be removed in a future version.”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Java ref type org.apache.spark.sql.SparkSession id 1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparkR.session()\n",
    "if (nchar(Sys.getenv(\"SPARK_HOME\")) < 1) {\n",
    "  Sys.setenv(SPARK_HOME = \"/home/spark\")\n",
    "}\n",
    "library(SparkR, lib.loc = c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\")))\n",
    "sparkR.session(master = \"local[*]\",\n",
    "               sparkConfig = list(spark.driver.memory = \"2g\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+-------+------+-------+----+\n",
      "|      date|  open|   high|    low| close| volume|Name|\n",
      "+----------+------+-------+-------+------+-------+----+\n",
      "|2014-05-05|  74.5|  74.66|  73.76| 74.51|4348608| BAX|\n",
      "|2014-01-14| 47.16| 47.894|  46.91|  47.8|2338221|ALLE|\n",
      "|2016-05-26|212.66|214.115| 210.23|212.05| 422492| ADS|\n",
      "|2016-05-18|210.84|  214.7|208.647|212.63| 893043| ADS|\n",
      "|2015-06-17|139.75|140.148| 139.08|139.76| 650779| BDX|\n",
      "+----------+------+-------+-------+------+-------+----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_raw <- loadDF(\n",
    "  path = \"/app/data/R/SparkR_test/SparkR_test/all_stocks_5yr.csv\", # File path\n",
    "  source = \"csv\", # file type\n",
    "  header = \"true\", # data have header or not\n",
    "  inferSchema = \"true\" # auto column type prediction\n",
    ")\n",
    "df <- repartition(df_raw, 5) # partition the data\n",
    "\n",
    "showDF(df, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|      date|  open|\n",
      "+----------+------+\n",
      "|2016-12-22|123.72|\n",
      "|2015-03-09|31.495|\n",
      "|2013-12-02| 23.55|\n",
      "|2014-01-22| 86.91|\n",
      "|2014-08-06|149.21|\n",
      "+----------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "temp <- SparkR::select(df, # Dataframe\n",
    "  c(\"date\", \"open\") # Column names to select\n",
    ")\n",
    "\n",
    "showDF(temp, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+------+------+-------+----+\n",
      "|      date|  open|   high|   low| close| volume|Name|\n",
      "+----------+------+-------+------+------+-------+----+\n",
      "|2014-05-05|  74.5|  74.66| 73.76| 74.51|4348608| BAX|\n",
      "|2014-01-14| 47.16| 47.894| 46.91|  47.8|2338221|ALLE|\n",
      "|2016-05-26|212.66|214.115|210.23|212.05| 422492| ADS|\n",
      "+----------+------+-------+------+------+-------+----+\n"
     ]
    }
   ],
   "source": [
    "# Select first 3 rows\n",
    "temp <- limit(df, 3)\n",
    "\n",
    "showDF(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-------+------+-------+----+\n",
      "|      date|  open|  high|    low| close| volume|Name|\n",
      "+----------+------+------+-------+------+-------+----+\n",
      "|2016-03-22|100.08|100.37| 99.455| 99.93|1435782| AMT|\n",
      "|2017-12-27|101.72|101.72|   99.4| 99.77| 988503| AAP|\n",
      "|2014-12-10|100.22| 101.1|  99.97|100.17|1826854| AMT|\n",
      "|2015-08-20|102.18|103.66|  99.87| 99.97|3459881| ACN|\n",
      "|2014-12-08| 104.0|104.17|99.6556|100.71|3484193|AVGO|\n",
      "+----------+------+------+-------+------+-------+----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "temp <- SparkR::filter(df, df$open > 100 & df$low < 100)\n",
    "\n",
    "showDF(temp, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType\n",
       "|-name = \"date\", type = \"DateType\", nullable = TRUE\n",
       "|-name = \"open\", type = \"DoubleType\", nullable = TRUE\n",
       "|-name = \"high\", type = \"DoubleType\", nullable = TRUE\n",
       "|-name = \"low\", type = \"DoubleType\", nullable = TRUE\n",
       "|-name = \"close\", type = \"DoubleType\", nullable = TRUE\n",
       "|-name = \"volume\", type = \"IntegerType\", nullable = TRUE\n",
       "|-name = \"Name\", type = \"StringType\", nullable = TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "schema(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+---------+\n",
      "|      date|Name|Metric|   Values|\n",
      "+----------+----+------+---------+\n",
      "|2014-05-05| BAX|  open|     74.5|\n",
      "|2014-05-05| BAX|  high|    74.66|\n",
      "|2014-05-05| BAX|   low|    73.76|\n",
      "|2014-05-05| BAX| close|    74.51|\n",
      "|2014-05-05| BAX|volume|4348608.0|\n",
      "+----------+----+------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Pivot Longer function\n",
    "pivot_longer_sparkr <- function(df, id_cols, name_col, value_col) {\n",
    "  library(SparkR)\n",
    "  # Get all column names from the DataFrame\n",
    "  all_cols <- colnames(df)\n",
    "  # Identify the columns to pivot by excluding the specified columns\n",
    "  cols_to_longer <- setdiff(all_cols, id_cols)\n",
    "  # Use stack to pivot the columns\n",
    "  long_df <- unpivot(df, id_cols, cols_to_longer, name_col, value_col)\n",
    "  return(long_df)\n",
    "}\n",
    "\n",
    "# Applying the function\n",
    "temp <- pivot_longer_sparkr(df, id_cols = c(\"date\", \"Name\"),\n",
    "                            name_col = \"Metric\", value_col = \"Values\")\n",
    "\n",
    "showDF(temp, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+---------+------------------+\n",
      "|      date|Name|Metric|   Values|        values_100|\n",
      "+----------+----+------+---------+------------------+\n",
      "|2014-05-05| BAX|  open|     74.5|             0.745|\n",
      "|2014-05-05| BAX|  high|    74.66|0.7465999999999999|\n",
      "|2014-05-05| BAX|   low|    73.76|            0.7376|\n",
      "|2014-05-05| BAX| close|    74.51|0.7451000000000001|\n",
      "|2014-05-05| BAX|volume|4348608.0|          43486.08|\n",
      "+----------+----+------+---------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "temp <- withColumn(\n",
    "    temp, \n",
    "    \"values_100\", \n",
    "    temp$Values/100\n",
    ")\n",
    "showDF(temp, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+---------+------------------+\n",
      "|      date|Name|Metric|   Values|        values_100|\n",
      "+----------+----+------+---------+------------------+\n",
      "|2014-05-05| BAX|  OPEN|     74.5|             0.745|\n",
      "|2014-05-05| BAX|   LOW|    73.76|            0.7376|\n",
      "|2014-05-05| BAX| CLOSE|    74.51|0.7451000000000001|\n",
      "|2014-05-05| BAX|VOLUME|4348608.0|          43486.08|\n",
      "|2014-01-09| AEE|  OPEN|    36.02|            0.3602|\n",
      "+----------+----+------+---------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "temp_new <- temp %>% \n",
    "  withColumn(\"Metric\", upper(temp$Metric)) %>% \n",
    "  SparkR::filter(rlike(temp$Metric, \"o\") & year(temp$date) != 2016)\n",
    "\n",
    "showDF(temp_new, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
